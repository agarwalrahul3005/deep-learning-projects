{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "***This notebook is developed by Prof. Monali Mavani***"
      ],
      "metadata": {
        "id": "md5aI3u3NIHC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook demonstates\n",
        "1. Create, train and evaluate Convolution Neural Network using torch.nn.Module\n",
        "\n",
        "Dataset: https://pytorch.org/vision/main/generated/torchvision.datasets.MNIST.html\n",
        "\n",
        "Reference : https://pytorch.org/"
      ],
      "metadata": {
        "id": "S06vbGlQKle5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1fbnQNziwAPd"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import time\n",
        "import datetime\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Initialize Parameters and Hyperparameters\n",
        "# Hyperparameters\n",
        "input_size = 28 * 28  # MNIST images are 28x28\n",
        "#hidden_size = 1024\n",
        "hidden_size = 256\n",
        "num_classes = 10      # MNIST has 10 classes (digits 0-9)\n",
        "learning_rate = 0.001\n",
        "batch_size = 64\n",
        "num_epochs = 5\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "vz9uAliqm83a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Transforms** are common image transformations. They can be chained together using Compose\n",
        "\n",
        "All transformations accept PIL Image, Tensor Image or batch of Tensor Images as input. Tensor Image is a tensor with (C, H, W) shape, where C is a number of channels, H and W are image height and width. Batch of Tensor Images is a tensor of (B, C, H, W) shape, where B is a number of images in the batch.\n",
        "\n",
        "**transforms.toTensor()** Converts a PIL Image or numpy.ndarray (H x W x C) in the range [0, 255] to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0]\n",
        "\n",
        "**transforms.Normalize((0.5,), (0.5,)** :  \n",
        "normalizes the data of [0,1] into [-1,1] scale by performing (input-0.5)/0.5, so [0,1]->[-1,1]"
      ],
      "metadata": {
        "id": "K03FkjHUCmkg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])"
      ],
      "metadata": {
        "id": "gemuQQNdC-PR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3KGt871Jigd",
        "outputId": "0228aca0-bcd7-4cac-c9a6-f78badd2df34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/drive/My Drive/Colab Notebooks/')"
      ],
      "metadata": {
        "id": "ltkYfkGYJnsV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Understanding torchvision datasets"
      ],
      "metadata": {
        "id": "_9JUQzBJOEY_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MNIST dataset (28x28 images of digits 0-9)\n",
        "\n",
        "train_dataset1 = torchvision.datasets.MNIST(root='./data', train=True, transform=None, download=False)\n",
        "test_dataset1 = torchvision.datasets.MNIST(root='./data', train=False, transform=None)\n",
        "\n",
        "len(train_dataset1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QpMNLYwLQN7",
        "outputId": "deebe10c-0be9-48f0-b37a-2263f78b6e98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_dataset1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCTbSpdiLhEa",
        "outputId": "a227b9cc-54c1-40db-b340-f7435d52accd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#first element is a PIL image and the second is an target\n",
        "train_dataset1[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBbON3xHLmoU",
        "outputId": "72e44413-bda4-4928-be50-1f4821ff569b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<PIL.Image.Image image mode=L size=28x28>, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_image_zero, train_target_zero = train_dataset1[0]\n",
        "train_image_zero\n",
        "print(train_image_zero.size)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOA_nIwyL-7s",
        "outputId": "8637cfb7-306e-41f0-b6de-f8585aa51b90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_image_zero.size)\n",
        "print(train_target_zero)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nps6g4oN_kZ",
        "outputId": "5b2a8814-958d-4b10-9391-8209b426581e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(28, 28)\n",
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### loading dataset using data loader"
      ],
      "metadata": {
        "id": "_cfucTDlOK-w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Load MNIST dataset and perform image pre processing\n",
        "# MNIST dataset (28x28 images of digits 0-9)\n",
        "\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transform)\n"
      ],
      "metadata": {
        "id": "WZ7tP9WcDCp3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JEwpQOjeLADZ",
        "outputId": "e6421650-93d9-4958-b563-98677b3cf5d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9765, -0.8588,\n",
              "           -0.8588, -0.8588, -0.0118,  0.0667,  0.3725, -0.7961,  0.3020,\n",
              "            1.0000,  0.9373, -0.0039, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -0.7647, -0.7176, -0.2627,  0.2078,  0.3333,  0.9843,\n",
              "            0.9843,  0.9843,  0.9843,  0.9843,  0.7647,  0.3490,  0.9843,\n",
              "            0.8980,  0.5294, -0.4980, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -0.6157,  0.8667,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,\n",
              "            0.9843,  0.9843,  0.9843,  0.9686, -0.2706, -0.3569, -0.3569,\n",
              "           -0.5608, -0.6941, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -0.8588,  0.7176,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,\n",
              "            0.5529,  0.4275,  0.9373,  0.8902, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -0.3725,  0.2235, -0.1608,  0.9843,  0.9843,  0.6078,\n",
              "           -0.9137, -1.0000, -0.6627,  0.2078, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -0.8902, -0.9922,  0.2078,  0.9843, -0.2941,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000,  0.0902,  0.9843,  0.4902,\n",
              "           -0.9843, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -0.9137,  0.4902,  0.9843,\n",
              "           -0.4510, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.7255,  0.8902,\n",
              "            0.7647,  0.2549, -0.1529, -0.9922, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.3647,\n",
              "            0.8824,  0.9843,  0.9843, -0.0667, -0.8039, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -0.6471,  0.4588,  0.9843,  0.9843,  0.1765, -0.7882, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -0.8745, -0.2706,  0.9765,  0.9843,  0.4667, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000,  0.9529,  0.9843,  0.9529, -0.4980,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -0.6392,  0.0196,  0.4353,  0.9843,  0.9843,  0.6235, -0.9843,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.6941,  0.1608,\n",
              "            0.7961,  0.9843,  0.9843,  0.9843,  0.9608,  0.4275, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -0.8118, -0.1059,  0.7333,  0.9843,\n",
              "            0.9843,  0.9843,  0.9843,  0.5765, -0.3882, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -0.8196, -0.4824,  0.6706,  0.9843,  0.9843,  0.9843,\n",
              "            0.9843,  0.5529, -0.3647, -0.9843, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.8588,\n",
              "            0.3412,  0.7176,  0.9843,  0.9843,  0.9843,  0.9843,  0.5294,\n",
              "           -0.3725, -0.9294, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "          [-1.0000, -1.0000, -1.0000, -1.0000, -0.5686,  0.3490,  0.7725,\n",
              "            0.9843,  0.9843,  0.9843,  0.9843,  0.9137,  0.0431, -0.9137,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "          [-1.0000, -1.0000, -1.0000, -1.0000,  0.0667,  0.9843,  0.9843,\n",
              "            0.9843,  0.6627,  0.0588,  0.0353, -0.8745, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
              "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
              "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000]]]),\n",
              " 5)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DataLoader()\n",
        "The Dataset retrieves our dataset’s features and labels one sample at a time. While training a model, we typically want to pass samples in “minibatches”, reshuffle the data at every epoch to reduce model overfitting, and use Python’s multiprocessing to speed up data retrieval.\n",
        "\n",
        "DataLoader is an iterable that abstracts this complexity for us in an easy API. PyTorch Dataloader is a utility class designed to simplify loading and iterating over datasets while training deep learning models. It has various constraints to iterating datasets, like batching, shuffling, and processing data"
      ],
      "metadata": {
        "id": "7F8YwBQktth3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DataLoader returns the batched data (input features and labels) to the training loop.\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "CL9gWD0bO4uh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#iterating over dataloader, each batch size is 10000\n",
        "i=0\n",
        "for X_batch, y_batch in train_loader:\n",
        "    #print(X_batch, y_batch)\n",
        "    print(X_batch.shape, y_batch.shape)\n",
        "    i=i+1\n",
        "    if i==1:\n",
        "      break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PoPaq_tTTJ-S",
        "outputId": "3a4c3513-45fd-4c5c-c415-9fde11bac993"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define the Neural Network using torch.nn.Module\n",
        "Base class for all neural network modules. Your models should also subclass this class.\n",
        "\n",
        "An nn.Module contains layers, and a method forward(input) that returns the output.\n",
        "\n",
        "https://pytorch.org/docs/stable/nn.html\n"
      ],
      "metadata": {
        "id": "ia9usP29UoVp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Define the CNN model\n",
        "class DNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5, padding=2)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2) #stride  is not specified by default, it is set equal to the pooling kernel size.\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, padding=2)\n",
        "        self.relu = nn.ReLU()\n",
        "           # Input size adjusted for the output of conv layers\n",
        "        self.fc3 = nn.Linear(7 * 7 * 64,hidden_size)  # if just one conv layer\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "        self.fc2 = nn.Linear(hidden_size, 10)  # 10 classes for digits 0-9\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)  # Pass the input through the first convolutional layer\n",
        "        x = self.relu(x)  # Apply ReLU activation\n",
        "        x = self.pool(x)  # Apply max pooling\n",
        "\n",
        "        x = self.conv2(x)  # Pass the output through the second convolutional layer\n",
        "        x = self.relu(x)  # Apply ReLU activation\n",
        "        x = self.pool(x)  # Apply max pooling\n",
        "\n",
        "\n",
        "        # Flatten the output of the convolutional layers for the fully connected layers\n",
        "        x = torch.flatten(x, 1)\n",
        "\n",
        "\n",
        "        #x = self.fc1(x)\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "YY9hT0rr596u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create an instance of  (Initialize the model), and move it to the device, and print its structure.\n",
        "model = DNN().to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MvtmmOz2VnbD",
        "outputId": "64a50daf-baf1-4f7a-9148-4e672e04a073"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DNN(\n",
            "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "  (relu): ReLU()\n",
            "  (fc3): Linear(in_features=3136, out_features=256, bias=True)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (fc2): Linear(in_features=256, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Returns the total number of elements in the input tensor.\n",
        "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(\"Total number of trainable model parameters:\", num_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqeUi-Z-TgsZ",
        "outputId": "a690976b-d9b5-4696-e684-0387dfd1aff8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of trainable model parameters: 857738\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "Wk1UBPXdDKlA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Train the model\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f'Starting epoch {epoch + 1}')\n",
        "    running_loss = 0.0\n",
        "\n",
        "    model.train() # Set the model to training mode\n",
        "   # i=0\n",
        "   # print(\"epoch no:\", epoch)\n",
        "    for i, batch in enumerate(train_loader,0):\n",
        "        #i=i+1\n",
        "\n",
        "        images, labels = batch\n",
        "        images, labels = images.to(device), labels.to(device) # Move the model to the device\n",
        "\n",
        "        # Forward propagate\n",
        "        outputs = model(images) # Forward pass\n",
        "        loss = criterion(outputs, labels) # Compute the loss\n",
        "\n",
        "        # Backpropagate\n",
        "        optimizer.zero_grad() # Zero the gradients\n",
        "        loss.backward() # Backward pass (compute gradients)\n",
        "\n",
        "       # Update parameters\n",
        "        optimizer.step() # Update model parameters\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 99:\n",
        "             print(f'batch {i+1}, Loss: {running_loss/100}')\n",
        "             running_loss = 0.0\n",
        "\n",
        "   # print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "end_time = time.time() # Record end time\n",
        "print('Training process has been completed. ')\n",
        "training_time = end_time - start_time\n",
        "\n",
        "print('Training time:', str(datetime.timedelta(seconds=training_time))) # for calculating the training time in minutes and seconds format\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Owdh9Ss5DNSg",
        "outputId": "d69bf613-781e-4c53-d57e-d37fa35d3e80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 1\n",
            "batch 100, Loss: 0.6612467194348574\n",
            "batch 200, Loss: 0.18559138283133506\n",
            "batch 300, Loss: 0.1441069777496159\n",
            "batch 400, Loss: 0.1357010205090046\n",
            "batch 500, Loss: 0.10418852601200342\n",
            "batch 600, Loss: 0.0967840416636318\n",
            "batch 700, Loss: 0.08494564363732934\n",
            "batch 800, Loss: 0.0720214920444414\n",
            "batch 900, Loss: 0.06952681160066276\n",
            "Starting epoch 2\n",
            "batch 100, Loss: 0.06930883675813675\n",
            "batch 200, Loss: 0.05575339860282838\n",
            "batch 300, Loss: 0.05692490827292204\n",
            "batch 400, Loss: 0.05783695822348818\n",
            "batch 500, Loss: 0.05758682055398822\n",
            "batch 600, Loss: 0.06358675364172087\n",
            "batch 700, Loss: 0.062300078297266734\n",
            "batch 800, Loss: 0.06406946506816893\n",
            "batch 900, Loss: 0.05902941734180786\n",
            "Starting epoch 3\n",
            "batch 100, Loss: 0.041709163072519005\n",
            "batch 200, Loss: 0.045649244928499685\n",
            "batch 300, Loss: 0.04100570324575528\n",
            "batch 400, Loss: 0.045426054960116743\n",
            "batch 500, Loss: 0.03869757210137323\n",
            "batch 600, Loss: 0.035657332440605385\n",
            "batch 700, Loss: 0.03977602682658471\n",
            "batch 800, Loss: 0.038570635032374415\n",
            "batch 900, Loss: 0.04309540114307311\n",
            "Starting epoch 4\n",
            "batch 100, Loss: 0.03418202412023675\n",
            "batch 200, Loss: 0.029572418146417475\n",
            "batch 300, Loss: 0.027747212427202614\n",
            "batch 400, Loss: 0.03716160061652772\n",
            "batch 500, Loss: 0.03886890142050106\n",
            "batch 600, Loss: 0.03723879700875841\n",
            "batch 700, Loss: 0.02865027816646034\n",
            "batch 800, Loss: 0.033199369568028485\n",
            "batch 900, Loss: 0.04291527551758918\n",
            "Starting epoch 5\n",
            "batch 100, Loss: 0.027102947756357024\n",
            "batch 200, Loss: 0.02333599049525219\n",
            "batch 300, Loss: 0.023843659592675977\n",
            "batch 400, Loss: 0.03106698311836226\n",
            "batch 500, Loss: 0.027515574628851028\n",
            "batch 600, Loss: 0.019356969014042987\n",
            "batch 700, Loss: 0.032584849453560306\n",
            "batch 800, Loss: 0.03125401725730626\n",
            "batch 900, Loss: 0.03001371844118694\n",
            "Training process has been completed. \n",
            "Training time: 0:01:18.236330\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Evaluate model performance\n",
        "model.eval() # Set the model to evaluation mode\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch in test_loader:\n",
        "        images, labels = batch\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1) #Get the predicted classes from the output logits\n",
        "\n",
        "        total += labels.size(0) #labels:Tensor with dimensions [no of samples in the batch, 1], labels.size(0) returns no of samples in a batch\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print(f'Accuracy of the model on the test images: {100 * correct / total:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ns7YxLVPDQjw",
        "outputId": "b85fe90b-d267-41d8-eeeb-52e6927aa113"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the model on the test images: 99.26%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 7: Use the model for inference\n",
        "sample_image, _ = test_dataset[6]  # Take the sixth test sample\n",
        "\n",
        "# Display the test image\n",
        "plt.imshow(sample_image.squeeze(), cmap='gray')  # Remove the batch dimension and display the image\n",
        "plt.title('Test Image')\n",
        "plt.show()\n",
        "\n",
        "# Add batch dimension and move the image to the device\n",
        "sample_image = sample_image.unsqueeze(0).to(device)  # Add batch dimension\n",
        "\n",
        "# Set model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Perform inference without tracking gradients\n",
        "with torch.no_grad():\n",
        "    prediction = model(sample_image)\n",
        "    predicted_label = torch.argmax(prediction, 1).item()  # Get the predicted class label\n",
        "    print(f'Predicted label for the first test image: {predicted_label}')\n"
      ],
      "metadata": {
        "id": "MyYUa87eo8sm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "outputId": "c6502815-734d-4832-fbe7-cb6c4bbeed90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted label for the first test image: 4\n"
          ]
        }
      ]
    }
  ]
}